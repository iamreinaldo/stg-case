[2025-10-16T02:04:48.104+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-10-16T02:04:48.118+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: ingest_to_bronze.parquet_to_snowflake manual__2025-10-16T02:03:46.996129+00:00 [queued]>
[2025-10-16T02:04:48.121+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: ingest_to_bronze.parquet_to_snowflake manual__2025-10-16T02:03:46.996129+00:00 [queued]>
[2025-10-16T02:04:48.121+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2025-10-16T02:04:48.126+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): parquet_to_snowflake> on 2025-10-16 02:03:46.996129+00:00
[2025-10-16T02:04:48.129+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=239) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-10-16T02:04:48.130+0000] {standard_task_runner.py:63} INFO - Started process 242 to run task
[2025-10-16T02:04:48.130+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'ingest_to_bronze', 'parquet_to_snowflake', 'manual__2025-10-16T02:03:46.996129+00:00', '--job-id', '34', '--raw', '--subdir', 'DAGS_FOLDER/api_ingest_to_bronze_dag.py', '--cfg-path', '/tmp/tmpcr77zeko']
[2025-10-16T02:04:48.131+0000] {standard_task_runner.py:91} INFO - Job 34: Subtask parquet_to_snowflake
[2025-10-16T02:04:48.137+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/***/settings.py:195 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-10-16T02:04:48.151+0000] {task_command.py:426} INFO - Running <TaskInstance: ingest_to_bronze.parquet_to_snowflake manual__2025-10-16T02:03:46.996129+00:00 [running]> on host 728de341d734
[2025-10-16T02:04:48.182+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='ingest_to_bronze' AIRFLOW_CTX_TASK_ID='parquet_to_snowflake' AIRFLOW_CTX_EXECUTION_DATE='2025-10-16T02:03:46.996129+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-16T02:03:46.996129+00:00'
[2025-10-16T02:04:48.182+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-10-16T02:04:48.188+0000] {connection.py:399} INFO - Snowflake Connector for Python Version: 3.10.1, Python Version: 3.12.4, Platform: Linux-6.10.14-linuxkit-aarch64-with-glibc2.36
[2025-10-16T02:04:48.188+0000] {connection.py:1239} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-10-16T02:04:49.204+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2025-10-16T02:04:49.340+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2025-10-16T02:04:49.456+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2025-10-16T02:04:49.457+0000] {logging_mixin.py:188} INFO - [snowflake ctx] ('ACCOUNTADMIN', 'COMPUTE_WH', 'COVID_DB', 'BRONZE')
[2025-10-16T02:04:49.459+0000] {logging_mixin.py:188} INFO - [load] BRONZE_DIR=/opt/***/data_lake/bronze | 5 parquet(s)
[2025-10-16T02:04:49.526+0000] {logging_mixin.py:188} INFO - [load] CASES_DATASET cols: ['ISO_CODE', 'CONTINENT', 'LOCATION', 'DATE', 'TOTAL_CASES', 'NEW_CASES', 'NEW_CASES_SMOOTHED', 'TOTAL_DEATHS', 'NEW_DEATHS', 'NEW_DEATHS_SMOOTHED', 'TOTAL_CASES_PER_MILLION', 'NEW_CASES_PER_MILLION', 'NEW_CASES_SMOOTHED_PER_MILLION', 'TOTAL_DEATHS_PER_MILLION', 'NEW_DEATHS_PER_MILLION', 'NEW_DEATHS_SMOOTHED_PER_MILLION']
[2025-10-16T02:04:49.527+0000] {logging_mixin.py:188} INFO - [load] create_sql: CREATE OR REPLACE TABLE "CASES_DATASET" ("ISO_CODE" TEXT, "CONTINENT" TEXT, "LOCATION" TEXT, "DATE" TIMESTAMP_NTZ, "TOTAL_CASES" FLOAT, "NEW_CASES" FLOAT, "NEW_CASES_SMOOTHED" FLOAT, "TOTAL_DEATHS" FLOAT, "NEW_DEATHS" FLOAT, "NEW_DEATHS_SMOOTHED" FLOAT, "TOTAL_CASES_PER_MILLION" FLOAT, "NEW_CASES_PER_MILLION" FLOAT, "NEW_CASES_SMOOTHED_PER_MILLION" FLOAT, "TOTAL_DEATHS_PER_MILLION" FLOAT, "NEW_DEATHS_PER_MILLION" FLOAT, "NEW_DEATHS_SMOOTHED_PER_MILLION" FLOAT)
[2025-10-16T02:04:49.866+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2025-10-16T02:04:50.044+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2025-10-16T02:04:58.325+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2025-10-16T02:04:58.327+0000] {logging_mixin.py:188} INFO - [load] CASES_DATASET: ok=True chunks=1 rows=424793
[2025-10-16T02:04:58.374+0000] {logging_mixin.py:188} INFO - [load] COUNTRY_DATASET cols: ['ISO_CODE', 'POPULATION_DENSITY', 'MEDIAN_AGE', 'AGED_65_OLDER', 'AGED_70_OLDER', 'GDP_PER_CAPITA', 'EXTREME_POVERTY', 'CARDIOVASC_DEATH_RATE', 'DIABETES_PREVALENCE', 'FEMALE_SMOKERS', 'MALE_SMOKERS', 'HANDWASHING_FACILITIES', 'HOSPITAL_BEDS_PER_THOUSAND', 'LIFE_EXPECTANCY', 'HUMAN_DEVELOPMENT_INDEX', 'POPULATION']
[2025-10-16T02:04:58.375+0000] {logging_mixin.py:188} INFO - [load] create_sql: CREATE OR REPLACE TABLE "COUNTRY_DATASET" ("ISO_CODE" TEXT, "POPULATION_DENSITY" TEXT, "MEDIAN_AGE" FLOAT, "AGED_65_OLDER" FLOAT, "AGED_70_OLDER" FLOAT, "GDP_PER_CAPITA" TEXT, "EXTREME_POVERTY" FLOAT, "CARDIOVASC_DEATH_RATE" FLOAT, "DIABETES_PREVALENCE" FLOAT, "FEMALE_SMOKERS" FLOAT, "MALE_SMOKERS" FLOAT, "HANDWASHING_FACILITIES" FLOAT, "HOSPITAL_BEDS_PER_THOUSAND" FLOAT, "LIFE_EXPECTANCY" FLOAT, "HUMAN_DEVELOPMENT_INDEX" FLOAT, "POPULATION" FLOAT)
[2025-10-16T02:04:58.795+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2025-10-16T02:04:58.990+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2025-10-16T02:05:01.646+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2025-10-16T02:05:01.648+0000] {logging_mixin.py:188} INFO - [load] COUNTRY_DATASET: ok=True chunks=1 rows=424777
[2025-10-16T02:05:01.687+0000] {logging_mixin.py:188} INFO - [load] HOSPITAL_DATASET cols: ['ISO_CODE', 'DATE', 'ICU_PATIENTS', 'ICU_PATIENTS_PER_MILLION', 'HOSP_PATIENTS', 'HOSP_PATIENTS_PER_MILLION', 'WEEKLY_ICU_ADMISSIONS', 'WEEKLY_ICU_ADMISSIONS_PER_MILLION', 'WEEKLY_HOSP_ADMISSIONS', 'WEEKLY_HOSP_ADMISSIONS_PER_MILLION']
[2025-10-16T02:05:01.688+0000] {logging_mixin.py:188} INFO - [load] create_sql: CREATE OR REPLACE TABLE "HOSPITAL_DATASET" ("ISO_CODE" TEXT, "DATE" TIMESTAMP_NTZ, "ICU_PATIENTS" FLOAT, "ICU_PATIENTS_PER_MILLION" FLOAT, "HOSP_PATIENTS" FLOAT, "HOSP_PATIENTS_PER_MILLION" FLOAT, "WEEKLY_ICU_ADMISSIONS" FLOAT, "WEEKLY_ICU_ADMISSIONS_PER_MILLION" FLOAT, "WEEKLY_HOSP_ADMISSIONS" FLOAT, "WEEKLY_HOSP_ADMISSIONS_PER_MILLION" FLOAT)
[2025-10-16T02:05:02.131+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2025-10-16T02:05:02.306+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2025-10-16T02:05:06.454+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2025-10-16T02:05:06.456+0000] {logging_mixin.py:188} INFO - [load] HOSPITAL_DATASET: ok=True chunks=1 rows=424793
[2025-10-16T02:05:06.496+0000] {logging_mixin.py:188} INFO - [load] TESTS_DATASET cols: ['ISO_CODE', 'DATE', 'TOTAL_TESTS', 'NEW_TESTS', 'NEW_TESTS_PER_THOUSAND', 'NEW_TESTS_SMOOTHED', 'NEW_TESTS_SMOOTHED_PER_THOUSAND', 'POSITIVE_RATE', 'TESTS_UNITS']
[2025-10-16T02:05:06.497+0000] {logging_mixin.py:188} INFO - [load] create_sql: CREATE OR REPLACE TABLE "TESTS_DATASET" ("ISO_CODE" TEXT, "DATE" TIMESTAMP_NTZ, "TOTAL_TESTS" FLOAT, "NEW_TESTS" FLOAT, "NEW_TESTS_PER_THOUSAND" FLOAT, "NEW_TESTS_SMOOTHED" FLOAT, "NEW_TESTS_SMOOTHED_PER_THOUSAND" FLOAT, "POSITIVE_RATE" FLOAT, "TESTS_UNITS" TEXT)
[2025-10-16T02:05:06.697+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2025-10-16T02:05:06.890+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2025-10-16T02:05:10.521+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2025-10-16T02:05:10.522+0000] {logging_mixin.py:188} INFO - [load] TESTS_DATASET: ok=True chunks=1 rows=424793
[2025-10-16T02:05:10.577+0000] {logging_mixin.py:188} INFO - [load] VACCINATION_DATASET cols: ['ISO_CODE', 'DATE', 'TOTAL_VACCINATIONS', 'PEOPLE_VACCINATED', 'PEOPLE_FULLY_VACCINATED', 'TOTAL_BOOSTERS', 'NEW_VACCINATIONS', 'NEW_VACCINATIONS_SMOOTHED', 'TOTAL_VACCINATIONS_PER_HUNDRED', 'PEOPLE_VACCINATED_PER_HUNDRED', 'PEOPLE_FULLY_VACCINATED_PER_HUNDRED', 'TOTAL_BOOSTERS_PER_HUNDRED', 'NEW_VACCINATIONS_SMOOTHED_PER_MILLION', 'NEW_PEOPLE_VACCINATED_SMOOTHED', 'NEW_PEOPLE_VACCINATED_SMOOTHED_PER_HUNDRED']
[2025-10-16T02:05:10.577+0000] {logging_mixin.py:188} INFO - [load] create_sql: CREATE OR REPLACE TABLE "VACCINATION_DATASET" ("ISO_CODE" TEXT, "DATE" TIMESTAMP_NTZ, "TOTAL_VACCINATIONS" FLOAT, "PEOPLE_VACCINATED" FLOAT, "PEOPLE_FULLY_VACCINATED" FLOAT, "TOTAL_BOOSTERS" FLOAT, "NEW_VACCINATIONS" FLOAT, "NEW_VACCINATIONS_SMOOTHED" FLOAT, "TOTAL_VACCINATIONS_PER_HUNDRED" FLOAT, "PEOPLE_VACCINATED_PER_HUNDRED" FLOAT, "PEOPLE_FULLY_VACCINATED_PER_HUNDRED" FLOAT, "TOTAL_BOOSTERS_PER_HUNDRED" FLOAT, "NEW_VACCINATIONS_SMOOTHED_PER_MILLION" FLOAT, "NEW_PEOPLE_VACCINATED_SMOOTHED" FLOAT, "NEW_PEOPLE_VACCINATED_SMOOTHED_PER_HUNDRED" FLOAT)
[2025-10-16T02:05:10.883+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2025-10-16T02:05:11.050+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2025-10-16T02:05:16.099+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2025-10-16T02:05:16.104+0000] {logging_mixin.py:188} INFO - [load] VACCINATION_DATASET: ok=True chunks=1 rows=424793
[2025-10-16T02:05:16.105+0000] {connection.py:762} INFO - closed
[2025-10-16T02:05:16.187+0000] {connection.py:768} INFO - No async queries seem to be running, deleting session
[2025-10-16T02:05:16.290+0000] {python.py:237} INFO - Done. Returned value was: None
[2025-10-16T02:05:16.292+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-10-16T02:05:16.312+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=ingest_to_bronze, task_id=parquet_to_snowflake, run_id=manual__2025-10-16T02:03:46.996129+00:00, execution_date=20251016T020346, start_date=20251016T020448, end_date=20251016T020516
[2025-10-16T02:05:16.351+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-10-16T02:05:16.362+0000] {taskinstance.py:3503} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-10-16T02:05:16.362+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
